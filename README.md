# Chest X-ray Multilabel Classification with CNNs and Vision Transformers

Questo progetto affronta il problema della **classificazione multilabel di immagini Chest X-ray** utilizzando sia **reti convoluzionali (DenseNet-121)** sia **Vision Transformer (ViT)**, con lâ€™obiettivo di confrontarne le prestazioni e analizzarne i comportamenti in ambito medicale.

---

## ğŸ“Œ Obiettivo

Dato un esame radiografico del torace, il modello deve predire **piÃ¹ patologie simultaneamente** (multilabel classification), un setting tipico in ambito clinico.

Il progetto si concentra su:
- Confronto CNN vs Transformer
- Analisi delle metriche multilabel
- Studio di problemi di class imbalance
- Training end-to-end con fine-tuning

---

## ğŸ§  Modelli Utilizzati

### 1ï¸âƒ£ DenseNet-121
- Pre-addestrata su ImageNet
- Feature extractor convoluzionale
- Classificatore finale `Linear â†’ BCEWithLogitsLoss`
- Fine-tuning completo di tutti i layer

### 2ï¸âƒ£ Simple Vision Transformer (ViT)
Implementazione custom di un Vision Transformer semplificato:
- Patch embedding (16Ã—16)
- Self-attention multi-head
- Residual connections + LayerNorm
- CLS token per classificazione globale
- Allenato from scratch sul dataset medicale

---

## ğŸ— Architettura ViT (schema concettuale)

```
Immagine
 â†“
Patch Embedding
 â†“
[ Transformer Block Ã— N ]
   â”œâ”€â”€ LayerNorm
   â”œâ”€â”€ Multi-Head Self-Attention
   â”œâ”€â”€ Skip Connection
   â”œâ”€â”€ LayerNorm
   â”œâ”€â”€ FeedForward (MLP)
   â””â”€â”€ Skip Connection
 â†“
CLS Token
 â†“
Linear Head
 â†“
Sigmoid (multilabel)
```

---

## ğŸ§ª Dataset

- Dataset di Chest X-ray con annotazioni multilabel
- Split: Training / Validation / Test
- Dataset fortemente sbilanciato (class imbalance)

---

## ğŸ”„ Data Augmentation & Preprocessing

### Training
- Resize (256)
- Random Resized Crop (224)
- Horizontal Flip
- Normalizzazione ImageNet

### Validation/Test
- Resize (256)
- Center Crop (224)
- Normalizzazione ImageNet

---

## âš™ï¸ Training Setup

- Loss: `BCEWithLogitsLoss`
- Optimizer:
  - DenseNet â†’ SGD + momentum
  - ViT â†’ AdamW
- Scheduler: StepLR
- Early stopping basato su AUROC macro
- Metriche multilabel con torchmetrics
- Logging con Weights & Biases (wandb)

---

## ğŸ“Š Metriche Utilizzate

- Accuracy (micro)
- Precision (micro)
- Recall (micro)
- F1-score (micro)
- F1-score (macro)
- AUROC (macro)

âš ï¸ Lâ€™accuracy non Ã¨ sufficiente in contesti multilabel sbilanciati.

---

## ğŸ“ˆ Risultati Migliori

### DenseNet-121
```
Accuracy (micro):   0.9303
Precision (micro):  0.6975
Recall (micro):     0.3073
F1 (micro):         0.4266
F1 (macro):         0.0487
AUROC (macro):      0.7021
Val loss:           0.1993
```

### Vision Transformer (SimpleViT)
```
Accuracy (micro):   0.9294
Precision (micro):  0.6728
Recall (micro):     0.3165
F1 (micro):         0.4305
F1 (macro):         0.0575
AUROC (macro):      0.7309
Val loss:           0.1981
```

---

## ğŸ§  Analisi dei Risultati

- Accuracy simile â†’ non discriminante
- ViT ottiene AUROC macro piÃ¹ alto
- ViT piÃ¹ sensibile alle classi rare
- DenseNet piÃ¹ conservativa (precision â†‘, recall â†“)
- In ambito medicale, alta sensibilitÃ  Ã¨ spesso preferibile

---

## ğŸš§ Limiti Attuali

- Forte class imbalance
- F1 macro ancora basso
- ViT allenato from scratch

---

## ğŸš€ Sviluppi Futuri

- Class-weighted BCE / Focal Loss
- Threshold tuning per classi
- Visualizzazione mappe di attenzione
- Pretraining self-supervised
- Ablation study

---

## ğŸ›  Tecnologie Utilizzate

- PyTorch
- Torchvision
- Torchmetrics
- Vision Transformers
- Weights & Biases
- NVIDIA CUDA

---

## ğŸ‘¨â€ğŸ’» Autore

Progetto sviluppato a scopo di studio e ricerca su CNN e Transformer in medical imaging.

---

## ğŸ“œ Licenza

Uso accademico / sperimentale.
